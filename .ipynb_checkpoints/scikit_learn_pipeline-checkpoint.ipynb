{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pipeline\n",
    "\n",
    "pipeline 实现了对全部步骤的流式化封装和管理，可以很方便地使参数集在新数据集上被重复使用。\n",
    "\n",
    "pipeline 可以用于下面几处：\n",
    "\n",
    "模块化 Feature Transform，只需写很少的代码就能将新的 Feature 更新到训练集中。\n",
    "\n",
    "自动化 Grid Search，只要预先设定好使用的 Model 和参数的候选，就能自动搜索并记录最佳的 Model。\n",
    "\n",
    "自动化 Ensemble Generation，每隔一段时间将现有最好的 K 个 Model 拿来做 Ensemble。\n",
    "\n",
    "要用 Pipeline 对训练集和测试集进行如下操作：\n",
    "\n",
    "1. 先用 StandardScaler 对数据集每一列做标准化处理，（是 transformer）\n",
    "2. 再用 PCA 将原始的 30 维度特征压缩的 2 维度，（是 transformer）\n",
    "3. 最后再用模型 LogisticRegression。（是 Estimator）\n",
    "4. 调用 Pipeline 时，输入由元组构成的列表，每个元组第一个值为变量名，元组第二个元素是 sklearn 中的 transformer \n",
    "或 Estimator。\n",
    "5. 注意中间每一步是 transformer，即它们必须包含 fit 和 transform 方法，或者 fit_transform。 \n",
    "6.最后一步是一个 Estimator，即最后一步模型要有 fit 方法，可以没有 transform 方法。\n",
    "\n",
    "Pipeline对象接受二元tuple构成的list，每一个二元 tuple 中的第一个元素为 arbitrary identifier string，我们用以获取（access）Pipeline object 中的 individual elements，二元 tuple 中的第二个元素是 scikit-learn与之相适配的transformer 或者 estimator。\n",
    "\n",
    "<img style=\"float: center;\"  src=\"sklearn_pipeline.png\"  width=\"80%\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score_train : 0.2875457875457875\n",
      "score_test : 0.35036496350364965\n",
      "[ True  True]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sensehiso/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn import svm\n",
    "from sklearn.feature_selection import f_regression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "# Breast Cancer Wisconsin dataset\n",
    "data = pd.read_csv('data/breast-cancer-wisconsin.csv', header=None)\n",
    "\n",
    "# 将?替换为标准缺失值表示，缺失值处理\n",
    "data = data.replace(to_replace='?', value=np.nan)\n",
    "\n",
    "# 丢弃带有缺失值的数据\n",
    "data = data.dropna(how='any')\n",
    "                                 \n",
    "\n",
    "X, y = data.values[:, 2:], data.values[:, 1]\n",
    "\n",
    "# y为字符型标签\n",
    "# 使用LabelEncoder类将其转换为0开始的数值型\n",
    "encoder = LabelEncoder()\n",
    "y = encoder.fit_transform(y)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2, random_state=0)\n",
    "\n",
    "\n",
    "anova_filter = SelectKBest(f_regression, k=5)\n",
    "# clf = svm.LinearSVR(kernel='linear')\n",
    "clf = svm.LinearSVC()\n",
    "anova_svm = Pipeline([('sc', StandardScaler()),\n",
    "            ('pca', PCA(n_components=2)),('anova', anova_filter), ('svc', clf)])\n",
    "# set_params 设置pipeline里的参数值　 \n",
    "anova_svm.set_params(anova__k=\"all\", svc__C=.1).fit(X_train, y_train)\n",
    "\n",
    "# prediction_trian = anova_svm.predict(X_train)\n",
    "# prediction_test = anova_svm.predict( X_test)\n",
    "score_train = anova_svm.score(X_train, y_train)\n",
    "score_test = anova_svm.score(X_test, y_test)\n",
    "\n",
    "# print(\"prediction_train :\", prediction_trian)\n",
    "# print(\"prediction_test :\", prediction_test)\n",
    "print(\"score_train :\", score_train)\n",
    "print(\"score_test :\", score_test)\n",
    "# getting the selected features chosen by anova_filter\n",
    "Pri_nameed_steps00 = anova_svm.named_steps['anova'].get_support()\n",
    "print(Pri_nameed_steps00)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sensehiso/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "df = pd.read_csv('data/bcw.csv', header=None)\n",
    "\n",
    "X, y = df.values[:, 2:], df.values[:, 1]\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "y = encoder.fit_transform(y)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2, random_state=0)\n",
    "\n",
    "\n",
    "pipe_lr = Pipeline([('sc', StandardScaler()),\n",
    "                    ('pca', PCA(n_components=2)),\n",
    "                    ('clf', LogisticRegression(random_state=1))\n",
    "                    ])\n",
    "pipe_lr.fit(X_train, y_train)\n",
    "print('Test accuracy: %.3f' % pipe_lr.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
